import logging
import sys
from functools import lru_cache
from typing import Any, Tuple

sys.path.insert(0, "/opt/airflow")

logger = logging.getLogger(__name__)

@lru_cache(maxsize=1)
def get_cached_services() -> Tuple[Any, Any, Any, Any, Any]:
    """Get cached service instances using lru_cache for automatic memoization.
    
    IMPORTANT: Imports are done INSIDE this function to avoid loading heavy
    dependencies (PyTorch, Docling, etc.) at module import time, which would
    cause Airflow DAG import timeouts.
    """
    # Import heavy dependencies only when function is called
    from src.db.factory import make_database
    from src.services.arxiv.factory import make_arxiv_client
    from src.services.metadata_fetcher import make_metadata_fetcher
    from src.services.opensearch.factory import make_opensearch_client
    from src.services.pdf_parser.factory import make_pdf_parser_service
    
    logger.info("Initializing cached services (first call only)")
    
    database = make_database()
    arxiv_client = make_arxiv_client()
    metadata_fetcher = make_metadata_fetcher()
    opensearch_client = make_opensearch_client()
    pdf_parser = make_pdf_parser_service()
    
    return arxiv_client, pdf_parser, database, metadata_fetcher, opensearch_client
